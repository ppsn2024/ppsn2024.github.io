---
title: Program
layout: page
lang: en
permalink: program/
description: Programm of PPSN 2024 conference
custom_css:
- timetable
---

<section class="background-light subpage-sec">
    <div class="container text-justify">
        <style>
            .subpage-sec {
                min-height: 0 !important;
            }

            table.info-table {
                word-wrap: break-word;
                word-break: break-word;
            }

            .info-table td:nth-child(4) {
                white-space: nowrap;
            }
        </style>
        <h2>Program</h2>

        <h3>Preliminary Timetable</h3>
        <br /><br />
        {% include dynamictimetable.html %}
        <br /><br />

        <h3>Keynotes</h3>
        <br />
        <div class="row">
            <div class="col-lg-5 col-md-12 col-sm-12">
                <img src="/assets/img/oliverschuetze-500.jpg" alt="Oliver Schuetze">
            </div>
            <div class="col-lg-7 col-md-12 col-sm-12">
                <p>
                    <b>Oliver Schütze</b> received a PhD in Mathematics from the University of Paderborn, Germany, in
                    2004. He is currently professor at the Cinvestav-IPN in Mexico City, Mexico. His research interests
                    focus on numerical and evolutionary optimization with an emphasis on multi-objective optimization
                    problems. He has co-authored more than 170 publications including 2 monographic books, 5 text books
                    and 17 edited books. Google Scholar reports more than 4,500 citations and a Hirsch index of 35.
                    During his career he received several prices and awards. For instance, he is co-author of two papers
                    that won the IEEE CIS Outstanding Paper Award (for the IEEE TEC papers of 2010 and 2012), and is
                    recipient of the H. S. Hsu Award 2022. He is Editor-in-Chief of the journal Mathematical and
                    Computational Applications, and member of the Editorial Board for Applied Soft Computing,
                    Computational Optimization and Applications, Engineering Optimization, Results in Control and
                    Optimization, and IEEE Transactions on Evolutionary Computation. He is founder of the workshop
                    series Numerical and Evolutionary Optimization (NEO). Dr. Schuetze is member of the Mexican Academy
                    of Sciences (AMC) and the National Network of Researchers (SNI Level III).
                    <br /><br />
                    For more information about Oliver Schütze go to <a href="https://neo.cinvestav.mx/Group/"
                        target="_blank">https://neo.cinvestav.mx/Group/</a>.
                </p>
            </div>
        </div>
        <br />

        <div class="row">
            <div class="col-lg-5 col-md-12 col-sm-12">
                <img src="/assets/img/bernardinoromeraparedes-500.png" alt="Bernardino Romera-Paredes">
            </div>
            <div class="col-lg-7 col-md-12 col-sm-12">
                <p>
                    <b>Bernardino Romera-Paredes</b> (Google DeepMind) is a former core team member of AlphaFold2 and
                    AlphaTensor and now research scientist at Google DeepMind in London. At PPSN 2024 Bernardino
                    Romera-Paredes will present his current research regarding the evolution of new heuristics,
                    supported by pairing a pre-trained LLM and an automated "evaluator", with his keynote "FunSearch:
                    Discovering new mathematics and algorithms using Large Language Models". In this talk I will present
                    FunSearch, a method to search for new solutions in mathematics and computer science. FunSearch works
                    by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer
                    code, with an automated “evaluator”, which guards against hallucinations and incorrect ideas. By
                    leveraging these two components within an evolutionary algorithm, initial solutions “evolve” into
                    new knowledge. I will present the application of FunSearch to a central problem in extremal
                    combinatorics — the cap set problem — where we discover new constructions of large cap sets going
                    beyond the best known ones, both in finite dimensional and asymptotic cases. This represents the
                    first discoveries made for established open problems using LLMs. Then, I will present the
                    application of FunSearch to an algorithmic problem, online bin packing, which showcases the
                    generality of the method. In this use case, FunSearch finds new heuristics that improve upon widely
                    used baselines. I will conclude the talk by discussing the implications of searching in the space of
                    code.
                    <br /><br />
                    For more information about Bernardino Romera-Paredes go to <a href="https://www.romera-paredes.com/"
                        target="_blank">https://www.romera-paredes.com/</a>.
                </p>
            </div>
        </div>
        <br />

        <div class="row">
            <div class="col-lg-5 col-md-12 col-sm-12">
                <img src="/assets/img/richardkueng.jpg" alt="Richard Kueng">
            </div>
            <div class="col-lg-7 col-md-12 col-sm-12">
                <p>
                    <b>Richard Kueng</b> (Johannes Kepler University Linz, AT) is full professor for Computing
                    Technologies. He pursues an interdisciplinary research agenda at the interface between computer
                    science (algorithms & computational complexity), physics (quantum information & quantum
                    technologies) and applied math (convex geometry & high dimensional probability theory). Broadly
                    speaking, he aspires to develop efficient and simple solutions for important algorithmic challenges
                    that also come with rigorous performance guarantees. Concrete examples are efficient subroutines for
                    quantum and classical data processing, as well as (convex) optimization. Applications in optics,
                    wireless communication, the math of voting and electronic design automation are also within his
                    portfolio. Together with Hsin-Yuan Huang and John Preskill (both at Caltech), Richard Kueng
                    developed the classical shadow formalism – an efficient quantum-to-classical conversion procedure
                    that has made a lasting impact on quantum computing technologies.
                    <br /><br />
                    In 2023, Richard Kueng received both an FWF START Award and an ERC Starting Grant. As of 2024, he's
                    also an elected member of the young wing of the Austrian Academy of Sciences.
                    <br /><br />
                    For more information about Richard Kueng go to <a href="https://iic.jku.at/team/kueng/"
                        target="_blank">https://iic.jku.at/team/kueng/</a>.
                </p>
            </div>
        </div>
        <br />

        <br />
        <h3>Workshops</h3>
        <div class="row">
            <div class="col-md-12">
                <table class="table text-start">
                    <thead>
                        <tr>
                            <th>Names</th>
                            <th>Title</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Benjamin Doerr, Concha Bielza, John McCall, and Weijie Zheng</td>
                            <td>30 Years of EDAs (more information at <a href="https://30yearsofedas.github.io"
                                    target="_blank">https://30yearsofedas.github.io</a>)</td>
                        </tr>
                        <tr>
                            <td>Tinkle Chugh, George De Ath, Paul Kent, Alma Rahat, Kaifeng Yang</td>
                            <td>BOSS: Bayesian and Surrogate-assisted Search and Optimisation</td>
                        </tr>
                        <tr>
                            <td>Heike Trautmann, Lennart Schapermeier, Oliver Schuetze</td>
                            <td>Multimodal Multi-objective Optimization</td>
                        </tr>
                        <tr>
                            <td>Carola Doerr, Vanessa Volz, Boris Naujoks, Olaf Mersmann, Mike Preuss, Pascal
                                Kerschk</td>
                            <td>Good Benchmarking Practices for Evolutionary Computation BENCHMARKING@PPSN2024</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <br />
        <h3>Tutorials</h3>
        <div class="row">
            <div class="col-md-12">
                <table class="table text-start">
                    <thead>
                        <tr>
                            <th>Names</th>
                            <th>Title</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Nelishia Pillay</td>
                            <td>Transfer Learning in Evolutionary Spaces</td>
                        </tr>
                        <tr>
                            <td>Ofer M. Shir</td>
                            <td>Mathematical Programming as a Complement to Bio-Inspired Optimization</td>
                        </tr>
                        <tr>
                            <td>Kate Smith-Miles and Mario Andrés Muñoz Acosta</td>
                            <td>Instance Space Analysis for Rigorous and Insightful Algorithm Testing</td>
                        </tr>
                        <tr>
                            <td>Chao Qian</td>
                            <td>Pareto Optimization for Subset Selection: Theories and Practical Algorithms</td>
                        </tr>
                        <tr>
                            <td>Benjamin Doerr</td>
                            <td>A Gentle Introduction to Theory (for Non-Theoreticians)</td>
                        </tr>
                        <tr>
                            <td>Michal Pluhacek, Adam Viktorin, Roman Senkerik</td>
                            <td>Large Language Models as Tools for Metaheuristic Design: Exploring Challenges and
                                Opportunities</td>
                        </tr>
                        <tr>
                            <td>A.E. Eiben</td>
                            <td>Robot Evolution</td>
                        </tr>
                        <tr>
                            <td>Ke Li</td>
                            <td>Decomposition Evolutionary Multi-Objective Optimization: What We Know from the
                                Literature and What We are not Clear from a Data Science Perspective</td>
                        </tr>
                        <tr>
                            <td>Michael Hellwig, Steffen Finck, and Hans-Georg Beyer</td>
                            <td>Introduction to Evolution Strategies for Constrained Optimization Problems</td>
                        </tr>
                        <tr>
                            <td>Martin Krejca</td>
                            <td>Theory of Estimation-of-Distribution Algorithms</td>
                        </tr>
                        <tr>
                            <td>Jeroen Rook, Manuel López-Ibáñez, and Heike Trautmann</td>
                            <td>Advanced Use of Automatic Algorithm Configuration: Single- and Multi-Objective
                                Approaches</td>
                        </tr>
                        <tr>
                            <td>Bogdan Filipič, Aljosa Vodopija</td>
                            <td>Constraint Handling in Multiobjective Optimization</td>
                        </tr>
                        <tr>
                            <td>Nikolaus Hansen</td>
                            <td>CMA-ES</td>
                        </tr>
                        <tr>
                            <td>Per Kristian Lehre</td>
                            <td>Runtime Analysis of Population-based Evolutionary Algorithms</td>
                        </tr>
                        <tr>
                            <td>Per Kristian Lehre, Mario A. Hevia Fajardo</td>
                            <td>Adversarial Optimisation through Competitive Co-evolutionary Algorithms</td>
                        </tr>
                        <tr>
                            <td>Anna V. Kononova, Niki van Stein, Diederick Vermetten</td>
                            <td>Structural bias in optimisation algorithms</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <br />
        <h3 id="acceptedpapers">Accepted Papers</h3>
        <div class="row">
            <div class="col-md-12">
                <table class="table text-start info-table">
                    <thead>
                        <tr>
                            <th>Authors</th>
                            <th>Title</th>
                            <th class="d-none d-sm-table-cell">Category</th>
                            <th>Session</th>
                        </tr>
                    </thead>
                    <tbody>
                        {% assign papers = site.data.papers.papers | sort: "slot_id"%}
                        {% for paper in papers %}
                        {% assign slot = site.data.timetable.slots | where: "id", paper.slot_id | first%}
                        <tr>
                            <td>{{paper.Authors}}</td>
                            <td>{{paper.Title}}</td>
                            <td class="d-none d-sm-table-cell">{{paper.Category}}</td>
                            <td>{{slot.title}}</td>
                        </tr>
                        {% endfor %}
                    </tbody>
                </table>
            </div>
        </div>
    </div>
</section>